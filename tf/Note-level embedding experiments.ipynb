{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Note-level embedding experiments\n",
    "\n",
    "Eamonn Bell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import collections\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import zipfile\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from six.moves import xrange  \n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`out.json` is a JSONified version of the pickled Bach dataset here:\n",
    "http://www-etud.iro.umontreal.ca/~boulanni/icml2012"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('out.json', 'r') as f:\n",
    "    d = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "229"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(d['train'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training data contains 229 pieces, represented as a list of lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[60, 72, 79, 88],\n",
       " [72, 79, 88],\n",
       " [67, 70, 76, 84],\n",
       " [69, 77, 86],\n",
       " [67, 70, 79, 88]]"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d['train'][0][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the tensorflow code expects a stream of words we flatten out this dataset into the `notes` list so that I can keep the `build_dataset()` function pretty similar to the original code. We don't use the `notes` list in coming up with our training examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "notes = []\n",
    "\n",
    "for piece in d['train']:\n",
    "    for chord in piece:\n",
    "        for index, note in enumerate(chord):\n",
    "            \n",
    "            notes.append(note)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of this code is based on this\n",
    "https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/tutorials/word2vec/word2vec_basic.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most common words (+UNK) [['UNK', 0], (79, 5759), (72, 4507), (67, 3858), (84, 3733)]\n",
      "First ten notes as ids:  [6, 2, 1, 20, 2, 1, 20, 3, 17, 7]\n",
      "First ten notes as midi numbers:  [60, 72, 79, 88, 72, 79, 88, 67, 70, 76]\n"
     ]
    }
   ],
   "source": [
    "def build_dataset(words, n_words):\n",
    "    \"\"\"Process raw inputs into a dataset.\"\"\"\n",
    "    count = [['UNK', -1]]\n",
    "    count.extend(collections.Counter(words).most_common(n_words - 1))\n",
    "    dictionary = dict()\n",
    "    for word, _ in count:\n",
    "        dictionary[word] = len(dictionary)\n",
    "    data = list()\n",
    "    unk_count = 0\n",
    "    for word in words:\n",
    "        if word in dictionary:\n",
    "            index = dictionary[word]\n",
    "        else:\n",
    "            index = 0  # dictionary['UNK']\n",
    "            unk_count += 1\n",
    "        data.append(index)\n",
    "    count[0][1] = unk_count\n",
    "    reversed_dictionary = dict(zip(dictionary.values(), dictionary.keys()))\n",
    "    return data, count, dictionary, reversed_dictionary\n",
    "\n",
    "data, count, dictionary, reverse_dictionary = build_dataset(notes,\n",
    "                                                            vocabulary_size)\n",
    "print('Most common words (+UNK)', count[:5])\n",
    "print('First ten notes as ids: ',data[:10])\n",
    "print('First ten notes as midi numbers: ', [reverse_dictionary[i] for i in data[:10]])\n",
    "\n",
    "data_index = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to rewrite the generate_batch function so that we can use it to build arbitrary target-context pairs based on the temporal structure of the dataset.\n",
    "\n",
    "The model expects `generate_batch` to return an `ndarray` `batch` of shape `batch_size` and another array, `labels` of `shape` (`batch_size`, 1) where batch is has the targets (inputs to logit) and labels has the contexts (outputs). \n",
    "\n",
    "NB This is the skip-gram framing of task: predict context given input.\n",
    "\n",
    "For megabig corpora we generate target/context pairs on the fly. I think we should be able precompute all the contexts and keep them in memory. There's not that many.\n",
    "\n",
    "This is the simplest context bank generator we could have:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_context_bank():\n",
    "    context_bank = []\n",
    "\n",
    "    # for every piece in the corpus\n",
    "    for piece in d['train']:\n",
    "        # ...look in each chord\n",
    "        for chord in piece:\n",
    "            # ...and for each note in each chord, the context\n",
    "            # is exactly those notes in that chord\n",
    "            # excluding the note currently under consideration\n",
    "            for index, note in enumerate(chord):\n",
    "                others = chord[:index] + chord[index+1:]\n",
    "                context_bank.append([dictionary[n] for n in others])\n",
    "    return context_bank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**The context for any note here is precisely those other notes happening at exactly the same time as the target.** This is where the context-building experimentation could happen (e.g. look back and forward one chord) which would tell us something about how notes in surrounding chords impact the makeup of the target chord."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "context_bank = simple_context_bank()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The context_bank has precomputed the contexts for every single observation (not scalable lol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(53824, 53824)"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data), len(context_bank)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, anytime I want a target-context pair, I can just go through this list, and choose a member of the second list at random."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_batch(batch_size, reuse_times, context_bank):\n",
    "    assert batch_size % reuse_times == 0\n",
    "    \n",
    "    # this isn't going to end well\n",
    "    global data_index\n",
    "    \n",
    "    batch = np.ndarray(shape=(batch_size), dtype=np.int32)\n",
    "    labels = np.ndarray(shape=(batch_size, 1), dtype=np.int32)\n",
    "    \n",
    "    batch_buffer = []\n",
    "    labels_buffer = []\n",
    "    \n",
    "    for i in range(batch_size // reuse_times):\n",
    "        # Very occasionaly the context is not defined\n",
    "        # this will cause the random.choice fxn to break\n",
    "        # lets use the UNK token for this \n",
    "\n",
    "        for _ in range(reuse_times):\n",
    "            if len(context_bank[data_index]) > 0:\n",
    "                target = random.choice(context_bank[data_index])\n",
    "            else:\n",
    "                target = dictionary['UNK']\n",
    "\n",
    "            batch_buffer.append(data[data_index])\n",
    "            labels_buffer.append(target)\n",
    "            \n",
    "        # loop around when necessary\n",
    "        data_index = (data_index + 1) % len(context_bank)\n",
    "        \n",
    "    batch = np.array(batch_buffer, dtype=np.int32)\n",
    "    labels = np.array(labels_buffer, dtype=np.int32).reshape((batch_size, 1))\n",
    "    \n",
    "    return batch, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset global to 0\n",
    "data_index = 0\n",
    "\n",
    "# tweak this\n",
    "batch_size = 64\n",
    "embedding_size = 50  # Dimension of the embedding vector.\n",
    "reuse_times = 4         # How many times to reuse an input to generate a label.\n",
    "\n",
    "# We pick a random validation set to sample nearest neighbors. Here we limit the\n",
    "# validation samples to the words that have a low numeric ID, which by\n",
    "# construction are also the most frequent.\n",
    "\n",
    "#valid_size = 16     # Random set of words to evaluate similarity on.\n",
    "#valid_window = 100  # Only pick dev samples in the head of the distribution.\n",
    "#valid_examples = np.random.choice(valid_window, valid_size, replace=False)\n",
    "\n",
    "num_sampled = 16    # Number of negative examples to sample.\n",
    "\n",
    "graph = tf.Graph()\n",
    "\n",
    "with graph.as_default():\n",
    "    train_inputs = tf.placeholder(tf.int32, shape=[batch_size])\n",
    "    train_labels = tf.placeholder(tf.int32, shape=[batch_size, 1])\n",
    "    with tf.device('/cpu:0'):\n",
    "        embeddings = tf.Variable(tf.random_uniform([vocabulary_size, embedding_size], -1.0, 1.0))\n",
    "        embed = tf.nn.embedding_lookup(embeddings, train_inputs)\n",
    "\n",
    "    nce_weights = tf.Variable(tf.truncated_normal([vocabulary_size, embedding_size], stddev=1.0 / math.sqrt(embedding_size)))\n",
    "    nce_biases = tf.Variable(tf.zeros([vocabulary_size]))\n",
    "\n",
    "  # Compute the average NCE loss for the batch.\n",
    "  # tf.nce_loss automatically draws a new sample of the negative labels each\n",
    "  # time we evaluate the loss.\n",
    "    loss = tf.reduce_mean(\n",
    "        tf.nn.nce_loss(weights=nce_weights,\n",
    "                 biases=nce_biases,\n",
    "                 labels=train_labels,\n",
    "                 inputs=embed,\n",
    "                 num_sampled=num_sampled,\n",
    "                 num_classes=vocabulary_size))\n",
    "\n",
    "    optimizer = tf.train.GradientDescentOptimizer(0.1).minimize(loss)\n",
    "    \n",
    "    norm = tf.sqrt(tf.reduce_sum(tf.square(embeddings), 1, keep_dims=True))\n",
    "    normalized_embeddings = embeddings / norm\n",
    "\n",
    "    # Add variable initializer.\n",
    "    init = tf.global_variables_initializer()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Double check that data_index is actually zero before training and regret using globals again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Begin training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Average loss at step 0, with 0 examples seen : 20.052600860595703\n",
      "Average loss at step 50, with 3200 examples seen : 14.916144409179687\n",
      "Average loss at step 100, with 6400 examples seen : 6.996801681518555\n",
      "Average loss at step 150, with 9600 examples seen : 4.646529269218445\n",
      "Average loss at step 200, with 12800 examples seen : 4.100311756134033\n",
      "Average loss at step 250, with 16000 examples seen : 3.697866144180298\n",
      "Average loss at step 300, with 19200 examples seen : 3.545483431816101\n",
      "Average loss at step 350, with 22400 examples seen : 3.5182483768463135\n",
      "Average loss at step 400, with 25600 examples seen : 3.4726358795166017\n",
      "Average loss at step 450, with 28800 examples seen : 3.3096796560287474\n",
      "Average loss at step 500, with 32000 examples seen : 3.2610220956802367\n",
      "Average loss at step 550, with 35200 examples seen : 3.5663054513931276\n",
      "Average loss at step 600, with 38400 examples seen : 3.3279019832611083\n",
      "Average loss at step 650, with 41600 examples seen : 3.52559045791626\n",
      "Average loss at step 700, with 44800 examples seen : 3.277328152656555\n",
      "Average loss at step 750, with 48000 examples seen : 3.2678736639022827\n",
      "Average loss at step 800, with 51200 examples seen : 3.240871858596802\n",
      "Average loss at step 850, with 54400 examples seen : 3.176290979385376\n",
      "Average loss at step 900, with 57600 examples seen : 3.1930544090271\n",
      "Average loss at step 950, with 60800 examples seen : 3.128720831871033\n",
      "Average loss at step 1000, with 64000 examples seen : 3.19367862701416\n"
     ]
    }
   ],
   "source": [
    "num_steps = 1001\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "  # We must initialize all variables before we use them.\n",
    "  init.run()\n",
    "  print('Initialized')\n",
    "\n",
    "  average_loss = 0\n",
    "  for step in xrange(num_steps):\n",
    "    batch_inputs, batch_labels = generate_batch(\n",
    "        batch_size, reuse_times, context_bank)\n",
    "    feed_dict = {train_inputs: batch_inputs, train_labels: batch_labels}\n",
    "\n",
    "    # We perform one update step by evaluating the optimizer op (including it\n",
    "    # in the list of returned values for session.run()\n",
    "    _, loss_val = session.run([optimizer, loss], feed_dict=feed_dict)\n",
    "    average_loss += loss_val\n",
    "\n",
    "    if step % 50 == 0:\n",
    "      if step > 0:\n",
    "        average_loss /= 50\n",
    "      # The average loss is an estimate of the loss over the last 2000 batches.\n",
    "      print(\"Average loss at step {}, with {} examples seen : {}\".format(step, step * batch_size, average_loss))\n",
    "      average_loss = 0\n",
    "\n",
    "  final_embeddings = normalized_embeddings.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55, 50)"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj = pca.fit_transform(final_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def midi_to_note_name(midi):\n",
    "    if midi == \"UNK\":\n",
    "        return midi\n",
    "    else:\n",
    "        chroma = midi % 12\n",
    "        octave = midi // 12\n",
    "        chromata = [\"C\", \"C#\", \"D\", \"E-\", \"E\", \"F\", \"F#\", \"G\", \"G#\", \"A\", \"B-\", \"B\"]\n",
    "        return \"{}{}\".format(chromata[chroma], octave)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C5'"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "midi_to_note_name(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "midiNotes = [midi_to_note_name(reverse_dictionary[i]) for i in range(len(reverse_dictionary))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55, 2)"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proj.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bokeh.plotting import figure, output_file, show, ColumnDataSource\n",
    "from bokeh.models import HoverTool, LabelSet\n",
    "from bokeh.io import output_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"http://bokeh.pydata.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"81c62b21-0c7f-41cd-bde1-f8a8122627cf\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(global) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "\n",
       "  if (typeof (window._bokeh_onload_callbacks) === \"undefined\" || force === true) {\n",
       "    window._bokeh_onload_callbacks = [];\n",
       "    window._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "\n",
       "  \n",
       "  if (typeof (window._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    window._bokeh_timeout = Date.now() + 5000;\n",
       "    window._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    if (window.Bokeh !== undefined) {\n",
       "      var el = document.getElementById(\"81c62b21-0c7f-41cd-bde1-f8a8122627cf\");\n",
       "      el.textContent = \"BokehJS \" + Bokeh.version + \" successfully loaded.\";\n",
       "    } else if (Date.now() < window._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function run_callbacks() {\n",
       "    window._bokeh_onload_callbacks.forEach(function(callback) { callback() });\n",
       "    delete window._bokeh_onload_callbacks\n",
       "    console.info(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(js_urls, callback) {\n",
       "    window._bokeh_onload_callbacks.push(callback);\n",
       "    if (window._bokeh_is_loading > 0) {\n",
       "      console.log(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.log(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    window._bokeh_is_loading = js_urls.length;\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      var s = document.createElement('script');\n",
       "      s.src = url;\n",
       "      s.async = false;\n",
       "      s.onreadystatechange = s.onload = function() {\n",
       "        window._bokeh_is_loading--;\n",
       "        if (window._bokeh_is_loading === 0) {\n",
       "          console.log(\"Bokeh: all BokehJS libraries loaded\");\n",
       "          run_callbacks()\n",
       "        }\n",
       "      };\n",
       "      s.onerror = function() {\n",
       "        console.warn(\"failed to load library \" + url);\n",
       "      };\n",
       "      console.log(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "    }\n",
       "  };var element = document.getElementById(\"81c62b21-0c7f-41cd-bde1-f8a8122627cf\");\n",
       "  if (element == null) {\n",
       "    console.log(\"Bokeh: ERROR: autoload.js configured with elementid '81c62b21-0c7f-41cd-bde1-f8a8122627cf' but no matching script tag was found. \")\n",
       "    return false;\n",
       "  }\n",
       "\n",
       "  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.5.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.5.min.js\"];\n",
       "\n",
       "  var inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    \n",
       "    function(Bokeh) {\n",
       "      \n",
       "    },\n",
       "    \n",
       "    function(Bokeh) {\n",
       "      \n",
       "      document.getElementById(\"81c62b21-0c7f-41cd-bde1-f8a8122627cf\").textContent = \"BokehJS is loading...\";\n",
       "    },\n",
       "    function(Bokeh) {\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-0.12.5.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.5.min.css\");\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.5.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.5.min.css\");\n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if ((window.Bokeh !== undefined) || (force === true)) {\n",
       "      for (var i = 0; i < inline_js.length; i++) {\n",
       "        inline_js[i](window.Bokeh);\n",
       "      }if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < window._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!window._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      window._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      var cell = $(document.getElementById(\"81c62b21-0c7f-41cd-bde1-f8a8122627cf\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (window._bokeh_is_loading === 0) {\n",
       "    console.log(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(js_urls, function() {\n",
       "      console.log(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(this));"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "output_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p = figure(plot_width=400, plot_height=400,\n",
    "           title=None, toolbar_location=\"below\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <div class=\"bk-plotdiv\" id=\"e282f9ad-a72a-4c93-8c19-28d65a668b7c\"></div>\n",
       "    </div>\n",
       "<script type=\"text/javascript\">\n",
       "  \n",
       "  (function(global) {\n",
       "    function now() {\n",
       "      return new Date();\n",
       "    }\n",
       "  \n",
       "    var force = false;\n",
       "  \n",
       "    if (typeof (window._bokeh_onload_callbacks) === \"undefined\" || force === true) {\n",
       "      window._bokeh_onload_callbacks = [];\n",
       "      window._bokeh_is_loading = undefined;\n",
       "    }\n",
       "  \n",
       "  \n",
       "    \n",
       "    if (typeof (window._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "      window._bokeh_timeout = Date.now() + 0;\n",
       "      window._bokeh_failed_load = false;\n",
       "    }\n",
       "  \n",
       "    var NB_LOAD_WARNING = {'data': {'text/html':\n",
       "       \"<div style='background-color: #fdd'>\\n\"+\n",
       "       \"<p>\\n\"+\n",
       "       \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "       \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "       \"</p>\\n\"+\n",
       "       \"<ul>\\n\"+\n",
       "       \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "       \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "       \"</ul>\\n\"+\n",
       "       \"<code>\\n\"+\n",
       "       \"from bokeh.resources import INLINE\\n\"+\n",
       "       \"output_notebook(resources=INLINE)\\n\"+\n",
       "       \"</code>\\n\"+\n",
       "       \"</div>\"}};\n",
       "  \n",
       "    function display_loaded() {\n",
       "      if (window.Bokeh !== undefined) {\n",
       "        var el = document.getElementById(\"e282f9ad-a72a-4c93-8c19-28d65a668b7c\");\n",
       "        el.textContent = \"BokehJS \" + Bokeh.version + \" successfully loaded.\";\n",
       "      } else if (Date.now() < window._bokeh_timeout) {\n",
       "        setTimeout(display_loaded, 100)\n",
       "      }\n",
       "    }\n",
       "  \n",
       "    function run_callbacks() {\n",
       "      window._bokeh_onload_callbacks.forEach(function(callback) { callback() });\n",
       "      delete window._bokeh_onload_callbacks\n",
       "      console.info(\"Bokeh: all callbacks have finished\");\n",
       "    }\n",
       "  \n",
       "    function load_libs(js_urls, callback) {\n",
       "      window._bokeh_onload_callbacks.push(callback);\n",
       "      if (window._bokeh_is_loading > 0) {\n",
       "        console.log(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "        return null;\n",
       "      }\n",
       "      if (js_urls == null || js_urls.length === 0) {\n",
       "        run_callbacks();\n",
       "        return null;\n",
       "      }\n",
       "      console.log(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "      window._bokeh_is_loading = js_urls.length;\n",
       "      for (var i = 0; i < js_urls.length; i++) {\n",
       "        var url = js_urls[i];\n",
       "        var s = document.createElement('script');\n",
       "        s.src = url;\n",
       "        s.async = false;\n",
       "        s.onreadystatechange = s.onload = function() {\n",
       "          window._bokeh_is_loading--;\n",
       "          if (window._bokeh_is_loading === 0) {\n",
       "            console.log(\"Bokeh: all BokehJS libraries loaded\");\n",
       "            run_callbacks()\n",
       "          }\n",
       "        };\n",
       "        s.onerror = function() {\n",
       "          console.warn(\"failed to load library \" + url);\n",
       "        };\n",
       "        console.log(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "        document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "      }\n",
       "    };var element = document.getElementById(\"e282f9ad-a72a-4c93-8c19-28d65a668b7c\");\n",
       "    if (element == null) {\n",
       "      console.log(\"Bokeh: ERROR: autoload.js configured with elementid 'e282f9ad-a72a-4c93-8c19-28d65a668b7c' but no matching script tag was found. \")\n",
       "      return false;\n",
       "    }\n",
       "  \n",
       "    var js_urls = [];\n",
       "  \n",
       "    var inline_js = [\n",
       "      function(Bokeh) {\n",
       "        (function() {\n",
       "          var fn = function() {\n",
       "            var docs_json = {\"5436ee6f-aceb-4bc2-8228-73361b07dfe1\":{\"roots\":{\"references\":[{\"attributes\":{\"data_source\":{\"id\":\"7e101e9b-04fd-4478-b184-e240aea98a9d\",\"type\":\"ColumnDataSource\"},\"glyph\":{\"id\":\"5e53af4c-e00c-403e-b80f-3df2fbd651ae\",\"type\":\"Circle\"},\"hover_glyph\":null,\"muted_glyph\":null,\"nonselection_glyph\":{\"id\":\"1a40b47c-cc6b-4aa0-a205-869b6804e3f5\",\"type\":\"Circle\"},\"selection_glyph\":null},\"id\":\"9185d2d3-d222-4566-bb4b-23fd1379e17d\",\"type\":\"GlyphRenderer\"},{\"attributes\":{\"dimension\":1,\"plot\":{\"id\":\"66a59e68-7997-4f71-810a-4419002edc5a\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"511a5342-7204-4607-b560-a8788fbba3b2\",\"type\":\"BasicTicker\"}},\"id\":\"5d782910-a6d0-486e-9fe1-bae9d122e506\",\"type\":\"Grid\"},{\"attributes\":{\"below\":[{\"id\":\"b8cd376f-d672-4ab2-97a5-d633348f35c6\",\"type\":\"LinearAxis\"}],\"left\":[{\"id\":\"b110543c-0abd-426e-a498-98f07f63489e\",\"type\":\"LinearAxis\"}],\"plot_height\":400,\"plot_width\":400,\"renderers\":[{\"id\":\"b8cd376f-d672-4ab2-97a5-d633348f35c6\",\"type\":\"LinearAxis\"},{\"id\":\"5812073d-29c3-4a41-8a9f-507938e07592\",\"type\":\"Grid\"},{\"id\":\"b110543c-0abd-426e-a498-98f07f63489e\",\"type\":\"LinearAxis\"},{\"id\":\"5d782910-a6d0-486e-9fe1-bae9d122e506\",\"type\":\"Grid\"},{\"id\":\"61d603ed-bc90-4aa2-ab89-651939a1da3d\",\"type\":\"BoxAnnotation\"},{\"id\":\"9185d2d3-d222-4566-bb4b-23fd1379e17d\",\"type\":\"GlyphRenderer\"},{\"id\":\"ad6205c5-5936-4dcd-88c5-da78680c1391\",\"type\":\"LabelSet\"}],\"title\":{\"id\":\"1ee8bfb7-56fc-4832-9e55-99b96c82d5df\",\"type\":\"Title\"},\"tool_events\":{\"id\":\"7790a739-2849-427c-8e4f-acae3d443215\",\"type\":\"ToolEvents\"},\"toolbar\":{\"id\":\"81c12886-b114-49df-8374-d9ba42829068\",\"type\":\"Toolbar\"},\"x_range\":{\"id\":\"2fe0ada2-ec34-400d-887a-12382c1c968d\",\"type\":\"DataRange1d\"},\"y_range\":{\"id\":\"f1bc90a3-1808-4a73-910a-e30b6012c4ab\",\"type\":\"DataRange1d\"}},\"id\":\"66a59e68-7997-4f71-810a-4419002edc5a\",\"subtype\":\"Figure\",\"type\":\"Plot\"},{\"attributes\":{},\"id\":\"7790a739-2849-427c-8e4f-acae3d443215\",\"type\":\"ToolEvents\"},{\"attributes\":{\"plot\":null,\"text\":\"\"},\"id\":\"1ee8bfb7-56fc-4832-9e55-99b96c82d5df\",\"type\":\"Title\"},{\"attributes\":{\"callback\":null},\"id\":\"f1bc90a3-1808-4a73-910a-e30b6012c4ab\",\"type\":\"DataRange1d\"},{\"attributes\":{\"plot\":{\"id\":\"66a59e68-7997-4f71-810a-4419002edc5a\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"b7f558b4-e0bf-4b00-b8e7-5954fd402783\",\"type\":\"BasicTicker\"}},\"id\":\"5812073d-29c3-4a41-8a9f-507938e07592\",\"type\":\"Grid\"},{\"attributes\":{\"active_drag\":\"auto\",\"active_scroll\":\"auto\",\"active_tap\":\"auto\",\"tools\":[{\"id\":\"8a232905-735e-4200-be23-c9c96c7daa9b\",\"type\":\"HoverTool\"},{\"id\":\"80902160-88db-4d7b-9b3f-078056570cab\",\"type\":\"BoxZoomTool\"},{\"id\":\"0147aac3-ec1d-4d2a-8eed-3f1715f91919\",\"type\":\"ResetTool\"}]},\"id\":\"81c12886-b114-49df-8374-d9ba42829068\",\"type\":\"Toolbar\"},{\"attributes\":{},\"id\":\"08afbd2f-c8b4-4f04-91c3-211b24479392\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{\"formatter\":{\"id\":\"08afbd2f-c8b4-4f04-91c3-211b24479392\",\"type\":\"BasicTickFormatter\"},\"plot\":{\"id\":\"66a59e68-7997-4f71-810a-4419002edc5a\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"b7f558b4-e0bf-4b00-b8e7-5954fd402783\",\"type\":\"BasicTicker\"}},\"id\":\"b8cd376f-d672-4ab2-97a5-d633348f35c6\",\"type\":\"LinearAxis\"},{\"attributes\":{\"plot\":{\"id\":\"66a59e68-7997-4f71-810a-4419002edc5a\",\"subtype\":\"Figure\",\"type\":\"Plot\"}},\"id\":\"0147aac3-ec1d-4d2a-8eed-3f1715f91919\",\"type\":\"ResetTool\"},{\"attributes\":{\"overlay\":{\"id\":\"61d603ed-bc90-4aa2-ab89-651939a1da3d\",\"type\":\"BoxAnnotation\"},\"plot\":{\"id\":\"66a59e68-7997-4f71-810a-4419002edc5a\",\"subtype\":\"Figure\",\"type\":\"Plot\"}},\"id\":\"80902160-88db-4d7b-9b3f-078056570cab\",\"type\":\"BoxZoomTool\"},{\"attributes\":{\"formatter\":{\"id\":\"a1e008d7-8c66-4f39-aca9-903740e84325\",\"type\":\"BasicTickFormatter\"},\"plot\":{\"id\":\"66a59e68-7997-4f71-810a-4419002edc5a\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"511a5342-7204-4607-b560-a8788fbba3b2\",\"type\":\"BasicTicker\"}},\"id\":\"b110543c-0abd-426e-a498-98f07f63489e\",\"type\":\"LinearAxis\"},{\"attributes\":{\"callback\":null},\"id\":\"2fe0ada2-ec34-400d-887a-12382c1c968d\",\"type\":\"DataRange1d\"},{\"attributes\":{},\"id\":\"511a5342-7204-4607-b560-a8788fbba3b2\",\"type\":\"BasicTicker\"},{\"attributes\":{\"level\":\"glyph\",\"plot\":{\"id\":\"66a59e68-7997-4f71-810a-4419002edc5a\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"source\":{\"id\":\"7e101e9b-04fd-4478-b184-e240aea98a9d\",\"type\":\"ColumnDataSource\"},\"text\":{\"field\":\"midiNotes\"},\"x\":{\"field\":\"xs\"},\"x_offset\":{\"value\":5},\"y\":{\"field\":\"ys\"},\"y_offset\":{\"value\":5}},\"id\":\"ad6205c5-5936-4dcd-88c5-da78680c1391\",\"type\":\"LabelSet\"},{\"attributes\":{},\"id\":\"b7f558b4-e0bf-4b00-b8e7-5954fd402783\",\"type\":\"BasicTicker\"},{\"attributes\":{\"bottom_units\":\"screen\",\"fill_alpha\":{\"value\":0.5},\"fill_color\":{\"value\":\"lightgrey\"},\"left_units\":\"screen\",\"level\":\"overlay\",\"line_alpha\":{\"value\":1.0},\"line_color\":{\"value\":\"black\"},\"line_dash\":[4,4],\"line_width\":{\"value\":2},\"plot\":null,\"render_mode\":\"css\",\"right_units\":\"screen\",\"top_units\":\"screen\"},\"id\":\"61d603ed-bc90-4aa2-ab89-651939a1da3d\",\"type\":\"BoxAnnotation\"},{\"attributes\":{\"fill_alpha\":{\"value\":0.1},\"fill_color\":{\"value\":\"#1f77b4\"},\"line_alpha\":{\"value\":0.1},\"line_color\":{\"value\":\"#1f77b4\"},\"x\":{\"field\":\"xs\"},\"y\":{\"field\":\"ys\"}},\"id\":\"1a40b47c-cc6b-4aa0-a205-869b6804e3f5\",\"type\":\"Circle\"},{\"attributes\":{},\"id\":\"a1e008d7-8c66-4f39-aca9-903740e84325\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{\"fill_color\":{\"value\":\"#1f77b4\"},\"line_color\":{\"value\":\"#1f77b4\"},\"x\":{\"field\":\"xs\"},\"y\":{\"field\":\"ys\"}},\"id\":\"5e53af4c-e00c-403e-b80f-3df2fbd651ae\",\"type\":\"Circle\"},{\"attributes\":{\"callback\":null,\"plot\":{\"id\":\"66a59e68-7997-4f71-810a-4419002edc5a\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"tooltips\":[[\"midiNotes\",\"@midiNotes\"]]},\"id\":\"8a232905-735e-4200-be23-c9c96c7daa9b\",\"type\":\"HoverTool\"},{\"attributes\":{\"callback\":null,\"column_names\":[\"xs\",\"ys\",\"midiNotes\"],\"data\":{\"midiNotes\":[\"UNK\",\"G6\",\"C6\",\"G5\",\"C7\",\"D6\",\"C5\",\"E6\",\"F6\",\"D7\",\"E-6\",\"A6\",\"A5\",\"B5\",\"F5\",\"B6\",\"E5\",\"B-5\",\"B-6\",\"D5\",\"E7\",\"E-5\",\"F7\",\"G7\",\"E-7\",\"G4\",\"G#5\",\"G#6\",\"A4\",\"B-4\",\"F4\",\"B4\",\"F#5\",\"F#6\",\"C4\",\"G#4\",\"C#6\",\"A7\",\"C#5\",\"E-4\",\"E4\",\"C#7\",\"D4\",\"F#7\",\"G#7\",\"F#4\",\"B-7\",\"C8\",\"B7\",\"C#4\",\"B-3\",\"G3\"],\"xs\":{\"__ndarray__\":\"oxbrZkVU4D9eeUEXd0TQvz6NBoT2zsu/+CdaLHWhwb/xxCHx6my2v/bDR3KRBMm/1L8zZMEf0b8oRntsLp3Rv5zTtNCENtO/r8MmqrVDtb+B7sLXPGTUPyV2GTGI0ce/Sy+bbMUc1b8gQJhN6M23v3SWj6poR9a/6BP7/lpoyL+57fc/84fRvwjAXjBUQL8/X3xE9W2BqL+W3GHQ4pPDv8zGu93x/sa/kJEy/w8sqz9UQEzl6WnSv7+VZZuR/9a/FgbPgBgArD/6NTeCAjnCvxSLdtkF37s/ayvEt4Pwhz85aJvwP5Gbv7DxjfQoHsY/pKgO55Flvj+sVcDK2yrIvwdOhOQikdi/pA+silSD0r8dud0jQTvHvw9Jy00ZDNA/W9wdYvE8hT8ZzZNS8c2jPwEM2cnfjbO/cFQeZhrZvz9LT2uo9yLTv8OMG0WzZMI/8vCCZhLBkD8p2TMbn3zVPxwpWuae9uQ/nutf+fwqtD/Dj6Imi1jFP2+EGOL099U/309QHGC12D+O/dLDcp7kP3bU/qsp8tI/iz6gwd9prD8=\",\"dtype\":\"float64\",\"shape\":[52]},\"ys\":{\"__ndarray__\":\"+4TXtgLTu78diKlk4ubUPwSVaqBMqMg/P1UZ4Je6wj+3PgTwBEzbP0NDjOKLkbs/9s9a9aM0wz/NREE7Mc+tv5DUhS0eMcS/2sOB1tqRzD8a3g1prgjSP2SOqeEVA44/jZt9FMwoyb+5H521CJDUPw2x51CJSLC/dgq7rb1e0b/5WNsGDvLcv+7fs/TgBss/f/PUk3Bsiz9XBY3IQVvRP036/nlG69S/eFB7T+312D/2l/PR7QrWvzwM5x8FlJK/L3iCm2syoz9vvk+OUMzBv1je5VJmqZc/l/i8D3VWzb/BdUC53JPFv9s+5S/UhLk/0BRss0jtxL9nAt3OR4TJP/vHl7Bqnry/1gN8M2vGsL+dZnfEjPvcPwWdrdzMquE/ZUY9t5N4ob9GaI3yoyG7vwVLvntmqr0/M2ebkrog0L9tz790np/CP4xohklWptG/teZZgLGHk78x8jWOc6jOP5mus8R0qle/+jjmGpJCrr+F8uoFoPHGP80VA7UibLy/tqS8y2Bxt7/I8GlUtYfSv6E6ubcwUIg/krWpcVAd4b8=\",\"dtype\":\"float64\",\"shape\":[52]}}},\"id\":\"7e101e9b-04fd-4478-b184-e240aea98a9d\",\"type\":\"ColumnDataSource\"}],\"root_ids\":[\"66a59e68-7997-4f71-810a-4419002edc5a\"]},\"title\":\"Bokeh Application\",\"version\":\"0.12.5\"}};\n",
       "            var render_items = [{\"docid\":\"5436ee6f-aceb-4bc2-8228-73361b07dfe1\",\"elementid\":\"e282f9ad-a72a-4c93-8c19-28d65a668b7c\",\"modelid\":\"66a59e68-7997-4f71-810a-4419002edc5a\"}];\n",
       "            \n",
       "            Bokeh.embed.embed_items(docs_json, render_items);\n",
       "          };\n",
       "          if (document.readyState != \"loading\") fn();\n",
       "          else document.addEventListener(\"DOMContentLoaded\", fn);\n",
       "        })();\n",
       "      },\n",
       "      function(Bokeh) {\n",
       "      }\n",
       "    ];\n",
       "  \n",
       "    function run_inline_js() {\n",
       "      \n",
       "      if ((window.Bokeh !== undefined) || (force === true)) {\n",
       "        for (var i = 0; i < inline_js.length; i++) {\n",
       "          inline_js[i](window.Bokeh);\n",
       "        }if (force === true) {\n",
       "          display_loaded();\n",
       "        }} else if (Date.now() < window._bokeh_timeout) {\n",
       "        setTimeout(run_inline_js, 100);\n",
       "      } else if (!window._bokeh_failed_load) {\n",
       "        console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "        window._bokeh_failed_load = true;\n",
       "      } else if (force !== true) {\n",
       "        var cell = $(document.getElementById(\"e282f9ad-a72a-4c93-8c19-28d65a668b7c\")).parents('.cell').data().cell;\n",
       "        cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "      }\n",
       "  \n",
       "    }\n",
       "  \n",
       "    if (window._bokeh_is_loading === 0) {\n",
       "      console.log(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "      run_inline_js();\n",
       "    } else {\n",
       "      load_libs(js_urls, function() {\n",
       "        console.log(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "        run_inline_js();\n",
       "      });\n",
       "    }\n",
       "  }(this));\n",
       "</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "source = ColumnDataSource(\n",
    "        data=dict(\n",
    "            xs=proj[:len(midiNotes),0],\n",
    "            ys=proj[:len(midiNotes),1],\n",
    "            midiNotes=midiNotes,\n",
    "        )\n",
    "    )\n",
    "\n",
    "hover = HoverTool(\n",
    "        tooltips=[\n",
    "            (\"midiNotes\", \"@midiNotes\"),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "labels = LabelSet(x='xs', y='ys', text='midiNotes', level='glyph',\n",
    "              x_offset=5, y_offset=5, source=source, render_mode='canvas')\n",
    "\n",
    "p = figure(plot_width=400, plot_height=400, tools=[hover, 'box_zoom', 'reset'])\n",
    "p.circle('xs', 'ys', source=source)\n",
    "\n",
    "p.add_layout(labels)\n",
    "\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
